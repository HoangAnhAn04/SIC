{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a75ea4f3-5a13-41a8-a62a-b674fe71548e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.9.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (8.1.7)\n",
      "Collecting dm-tree (from tensorflow_datasets)\n",
      "  Downloading dm_tree-0.1.8-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting immutabledict (from tensorflow_datasets)\n",
      "  Downloading immutabledict-4.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.26.4)\n",
      "Collecting promise (from tensorflow_datasets)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (3.20.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (5.9.0)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (14.0.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.31.0)\n",
      "Collecting simple-parsing (from tensorflow_datasets)\n",
      "  Downloading simple_parsing-0.1.5-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting tensorflow-metadata (from tensorflow_datasets)\n",
      "  Downloading tensorflow_metadata-1.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: termcolor in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (2.4.0)\n",
      "Requirement already satisfied: toml in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (4.65.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from tensorflow_datasets) (1.14.1)\n",
      "Collecting etils>=1.9.1 (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets)\n",
      "  Downloading etils-1.9.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (2023.10.0)\n",
      "Collecting importlib_resources (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (4.9.0)\n",
      "Requirement already satisfied: zipp in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from etils[enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from click->tensorflow_datasets) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\hoang\\anaconda3\\lib\\site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Collecting docstring-parser~=0.15 (from simple-parsing->tensorflow_datasets)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting googleapis-common-protos<2,>=1.56.4 (from tensorflow-metadata->tensorflow_datasets)\n",
      "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf>=3.20 (from tensorflow_datasets)\n",
      "  Downloading protobuf-4.25.4-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Downloading tensorflow_datasets-4.9.6-py3-none-any.whl (5.1 MB)\n",
      "   ---------------------------------------- 0.0/5.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.1 MB 1.4 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.1/5.1 MB 1.7 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.3/5.1 MB 2.0 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.5/5.1 MB 2.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.9/5.1 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.3/5.1 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.9/5.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.4/5.1 MB 6.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.0/5.1 MB 7.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.5/5.1 MB 7.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.1/5.1 MB 8.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.6/5.1 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.1/5.1 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.1/5.1 MB 8.4 MB/s eta 0:00:00\n",
      "Downloading etils-1.9.2-py3-none-any.whl (161 kB)\n",
      "   ---------------------------------------- 0.0/161.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 161.5/161.5 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading dm_tree-0.1.8-cp311-cp311-win_amd64.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 101.3/101.3 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading simple_parsing-0.1.5-py3-none-any.whl (113 kB)\n",
      "   ---------------------------------------- 0.0/113.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 113.6/113.6 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading tensorflow_metadata-1.15.0-py3-none-any.whl (28 kB)\n",
      "Downloading protobuf-4.25.4-cp310-abi3-win_amd64.whl (413 kB)\n",
      "   ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
      "   --------------------------------------  409.6/413.4 kB 12.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 413.4/413.4 kB 6.5 MB/s eta 0:00:00\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "   ---------------------------------------- 0.0/220.0 kB ? eta -:--:--\n",
      "   --------------------------------------  215.0/220.0 kB 13.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 220.0/220.0 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21544 sha256=1816693a625358931f7dea5beb865ffffc06447285564391f28248245d7ca286\n",
      "  Stored in directory: c:\\users\\hoang\\appdata\\local\\pip\\cache\\wheels\\90\\74\\b1\\9b54c896b8d9409e9268329d4d45ede8a8040abe91c8879932\n",
      "Successfully built promise\n",
      "Installing collected packages: dm-tree, protobuf, promise, importlib_resources, immutabledict, etils, docstring-parser, simple-parsing, googleapis-common-protos, tensorflow-metadata, tensorflow_datasets\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "Successfully installed dm-tree-0.1.8 docstring-parser-0.16 etils-1.9.2 googleapis-common-protos-1.63.2 immutabledict-4.2.0 importlib_resources-6.4.0 promise-2.3 protobuf-4.25.4 simple-parsing-0.1.5 tensorflow-metadata-1.15.0 tensorflow_datasets-4.9.6\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd67579-ab30-476e-8ad1-8e50e4a6b68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "544d87a2-ac40-474f-a522-de73b73b7adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'test'])\n"
     ]
    }
   ],
   "source": [
    "mnist_bldr = tfds.builder('mnist')\n",
    "mnist_bldr.download_and_prepare()\n",
    "datasets = mnist_bldr.as_dataset(shuffle_files=False)\n",
    "print(datasets.keys())\n",
    "mnist_train_orig, mnist_test_orig = datasets['train'], datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f3765a6-5a99-4076-a0b9-25955b359a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd1ff5b4-d9ea-4101-a4a4-af8155adc83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = mnist_train_orig.map(\n",
    "    lambda item: (tf.cast(item['image'], tf.float32)/255.0, tf.cast(item['label'], tf.int32)))\n",
    "mnist_test = mnist_test_orig.map(\n",
    "    lambda item: (tf.cast(item['image'], tf.float32)/255.0, tf.cast(item['label'], tf.int32)))\n",
    "tf.random.set_seed(1)\n",
    "mnist_train = mnist_train.shuffle(buffer_size=BUFFER_SIZE,\n",
    "                                  reshuffle_each_iteration=False)\n",
    "mnist_valid = mnist_train.take(10000).batch(BATCH_SIZE)\n",
    "mnist_train = mnist_train.skip(10000).batch(BATCH_SIZE)\n",
    "    \n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcc4f4f5-ed4e-4c4b-92fb-0e6982753219",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(\n",
    "    filters=32, kernel_size=(5,5),\n",
    "    strides=(1, 1), padding='same',\n",
    "    data_format='channels_last',\n",
    "    name='conv_1', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(\n",
    "    pool_size=(2, 2), name='pool_1'))\n",
    "model.add(tf.keras.layers.Conv2D(\n",
    "    filters=64, kernel_size=(5,5),\n",
    "    strides=(1, 1), padding='same',\n",
    "    name='conv_2', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), name='pool_2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a5ead64-4883-4fe8-803a-5332e5beb637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 7, 7, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_output_shape(input_shape=(16, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad4827fd-7839-434b-bfd1-66b7fa06d4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 3136)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add(tf.keras.layers.Flatten())\n",
    "model.compute_output_shape(input_shape=(16, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58045ade-cd47-4cc5-8f70-076dbace4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(\n",
    "    units=1024, name='fc_1',\n",
    "    activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(\n",
    "    rate=0.5))\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=10, name='fc_2',\n",
    "    activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84ccf51b-bf21-4d78-838d-46ccdafb8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> tf.random.set_seed(1)\n",
    ">>> model.build(input_shape=(None, 28, 28, 1))\n",
    ">>> model.compile(\n",
    "     optimizer=tf.keras.optimizers.Adam(),\n",
    "     loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316f9fc9-644b-4b3a-8c1a-18f12fe3d764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
